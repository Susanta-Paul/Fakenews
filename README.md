
# HinglishMemeX: Multimodal Fake News & Satire Classification in Hinglish Memes

HinglishMemeX is a multimodal deep learning pipeline that classifies Hinglish memes into four categories: **Real**, **Fake**, **Satire**, and **Partially True**.  
It combines **CLIP** for visual feature extraction with **IndicBERT** for text understanding, enabling robust classification of meme-based misinformation.

---

## ğŸ“Œ Features

- **Multimodal architecture**: Combines image and text encoders for richer contextual understanding.
- **Pretrained backbones**:  
  - Image Encoder: `openai/clip-vit-base-patch32`  
  - Text Encoder: `ai4bharat/indic-bert`
- **4-class classification**:
  - `real`
  - `fake`
  - `satire`
  - `partially true`
- **CLIP-style image preprocessing** and **tokenization for Hinglish**.
- **W&B (Weights & Biases)** integration for experiment tracking.
- **Training, validation, and testing pipelines** with early stopping.
- **Evaluation reports** including classification metrics, confusion matrix, and per-class performance.

---

## ğŸ“‚ Project Structure

HinglishMemeX/
â”‚
â”œâ”€â”€ HinglishMemeX.ipynb # Main training and evaluation notebook
â”œâ”€â”€ dataset_split_final/ # Dataset splits (train/val/test)
â”‚ â”œâ”€â”€ dataset_splits/
â”‚ â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â”‚ â”œâ”€â”€ annotations/ # JSONL annotation files
â”‚ â”‚ â”‚ â”œâ”€â”€ images/ # Meme images
â”‚ â”‚ â”œâ”€â”€ val/
â”‚ â”‚ â”œâ”€â”€ test/
â”‚
â”œâ”€â”€ best_model.pt # Saved best model
â”œâ”€â”€ wandb/ # W&B experiment logs
â””â”€â”€ test_predictions.csv # Model predictions on test set


#ğŸ› ï¸ Installation
1. Clone the repository:

```bash
git clone https://github.com/your-username/HinglishMemeX.git
cd HinglishMemeX
```

2. Install dependencies:
```bash
pip install torch torchvision transformers wandb scikit-learn matplotlib seaborn pandas pillow tqdm
```

# 1ï¸âƒ£ Data Preparation

# 2ï¸âƒ£ Training
1. Inside the notebook (HinglishMemeX.ipynb)
2. Load dataset splits
3. Initialize MultimodalClassifier
4. Train with W&B logging
5. Early stopping enabled for better generalization


# 3ï¸âƒ£ Evaluation
1. After training, the notebook
2. Loads the best saved model
3. Evaluates on the test set
4. Generates classification report & confusion matrix
5. Saves predictions to test_predictions.csv

# ğŸ§  Model Architecture
1. Image Encoder: CLIP Vision Transformer (clip-vit-base-patch32)
2. Text Encoder: IndicBERT (ai4bharat/indic-bert)
3. Projection Layers: Reduce embeddings to a unified hidden dimension
4. Fusion Layer: Concatenate image & text embeddings
5. Classification Head: Fully connected layers â†’ softmax output





